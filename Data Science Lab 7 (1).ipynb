{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwFfnQgbXJ_F"
   },
   "source": [
    "# Data Science Lab: Lab 7 part III (of III)\n",
    "\n",
    "Submit:\n",
    "\n",
    "A pdf of your notebook with solutions.\n",
    "A link to your colab notebook or also upload your .ipynb if not working on colab.\n",
    "\n",
    "# Goals of this Lab: Fine Tuning and Transfer Learning\n",
    "\n",
    "This assignment completes our segment on convolutional networks, computer vision and transfer learning. The goal of this colab notebook and lab is to get down the basics of Transfer learning, and harnessing the power of pre-trained notebooks, in a more substantial setting than CIFAR-10. Along the way, we get experience with creating and labeling data sets, and a number of other Python tools.\n",
    "\n",
    "Specifically, we do the following:\n",
    "\n",
    "* In this colab notebook, we create our own labeled image data set, with calls to the Bing API. We use this to download images with user-specified labels, into train and test directories.\n",
    "\n",
    "* We preprocess all the images and use the directory names as lables to create our training and testing data sets.\n",
    "\n",
    "* Then we download a pre-trained convolutional neural network from Pytorch. There is wide selection here. These have been trained on ImageNet. See references below.\n",
    "\n",
    "* Then we add a new last layer, and train. Note that the last layer we add has to have the right size, namely, the number of classes in our data.\n",
    "\n",
    "* Things to play with: Choosing different pre-trained models; Fine tuning the entire network vs freezing and fine tuning only the last layer or layers; Possibly adding more of our own layers at the end. (See the last optional problem at the end).\n",
    "\n",
    "\n",
    "Some references:\n",
    "\n",
    "The bing image downloader package from here https://pypi.org/project/bing-image-downloader/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxSFt4vWr7Bl"
   },
   "source": [
    "# The following will allow us to call the Bing Image Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9968,
     "status": "ok",
     "timestamp": 1707159623117,
     "user": {
      "displayName": "Constantine Caramanis",
      "userId": "18159196114040275437"
     },
     "user_tz": 360
    },
    "id": "AHSCfFin4A9F",
    "outputId": "a35ce390-5296-4e69-8278-7fb0159ed70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bing-image-downloader\n",
      "  Downloading bing_image_downloader-1.1.2-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: bing-image-downloader\n",
      "Successfully installed bing-image-downloader-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bing-image-downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8671,
     "status": "ok",
     "timestamp": 1707159654883,
     "user": {
      "displayName": "Constantine Caramanis",
      "userId": "18159196114040275437"
     },
     "user_tz": 360
    },
    "id": "envKo0eyXGK3",
    "outputId": "71d7cad6-510f-4746-f54c-918b573b37a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7bdb1a7f70d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import requests\n",
    "from bing_image_downloader import downloader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZguqCTTj8pl3"
   },
   "source": [
    "# Downloading the images we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlryPce8MXC5"
   },
   "outputs": [],
   "source": [
    "# These are the functions we need for asking for query terms, number of images\n",
    "# and the fraction of train/test split\n",
    "def get_query_terms():\n",
    "    \"\"\"Ask the user for a list of query terms.\"\"\"\n",
    "    queries = input(\"Enter query terms separated by commas: \").split(',')\n",
    "    return [query.strip() for query in queries]\n",
    "\n",
    "\n",
    "def get_positive_integers():\n",
    "    \"\"\"Ask the user for a list of positive integers.\"\"\"\n",
    "    while True:\n",
    "        numbers = input(\"Enter positive integers corresponding to each query, separated by commas: \").split(',')\n",
    "        try:\n",
    "            # Convert string inputs to integers\n",
    "            numbers = [int(num.strip()) for num in numbers]\n",
    "\n",
    "            # Check if all numbers are positive\n",
    "            if all(num > 0 for num in numbers):\n",
    "                return numbers\n",
    "            else:\n",
    "                print(\"All numbers must be positive. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter integers only.\")\n",
    "\n",
    "\n",
    "def get_train_test_proportion():\n",
    "    \"\"\"Ask the user for a number between 0 and 1 and ensure it is in that range.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Ask the user for a number and try to convert it to a float\n",
    "            num = float(input(\"What fraction of the data should be training? For example, enter 0.75 for 75 percent: \"))\n",
    "\n",
    "            # Check if the number is between 0 and 1 (inclusive)\n",
    "            if 0 <= num <= 1:\n",
    "                return num\n",
    "            else:\n",
    "                print(\"The number must be between 0 and 1. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number between 0 and 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g4tRkN3ve4N"
   },
   "source": [
    "# Problem 0\n",
    "\n",
    "Run the above code, and the code below, to make your own data set. Choose terms that aren't already one of the 1000 classes in the Imagenet dataset.\n",
    "\n",
    "I recommend starting small: 2 or 3 different terms, and maybe 100-200 images max from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O37G06MWMxDv"
   },
   "outputs": [],
   "source": [
    "queries = get_query_terms()\n",
    "# And the number of each\n",
    "numbers = get_positive_integers()\n",
    "# And the fraction of training data\n",
    "frac_train = get_train_test_proportion()\n",
    "# Check if number of queries matches number of positive integers\n",
    "if len(queries) != len(numbers):\n",
    "  print(\"Number of queries and integers do not match!\")\n",
    "\n",
    "for query, n in zip(queries, numbers):\n",
    "    # Download all images to a common directory\n",
    "    downloader.download(query, limit=n, output_dir='dataset/all_images', adult_filter_off=True, force_replace=False, timeout=60, verbose=False)\n",
    "\n",
    "    # Directory paths\n",
    "    source_dir = f'dataset/all_images/{query}'\n",
    "    train_dir = f'dataset/train/{query}'\n",
    "    test_dir = f'dataset/test/{query}'\n",
    "\n",
    "    # Create train and test directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Get all downloaded files\n",
    "    all_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir)]\n",
    "    random.shuffle(all_files)  # Shuffle to randomize distribution\n",
    "\n",
    "    # Determine split counts\n",
    "    n_train = int(math.floor(len(all_files) * frac_train))\n",
    "    train_files = all_files[:n_train]\n",
    "    test_files = all_files[n_train:]\n",
    "\n",
    "    # Move files to respective directories\n",
    "    for f in train_files:\n",
    "        shutil.move(f, train_dir)\n",
    "    for f in test_files:\n",
    "        shutil.move(f, test_dir)\n",
    "\n",
    "    # Optionally, remove the source directory if it's now empty\n",
    "    if not os.listdir(source_dir):\n",
    "        os.rmdir(source_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5lbtgMdqmPi"
   },
   "source": [
    "# Let's make sure we downloaded enough of each\n",
    "\n",
    "The code above is just making calls to the Bing API, and as you'll see there are a number of errors. So we should make sure that we have in fact downloaded the images we need. Print the number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVrD8wGrqCpF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_directory(directory, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively counts the number of files in each directory and subdirectory.\n",
    "\n",
    "    Args:\n",
    "    - directory: The directory path to start counting from.\n",
    "    - prefix: A string used for indentation to visualize the folder structure.\n",
    "    \"\"\"\n",
    "    num_files = sum([len(files) for r, d, files in os.walk(directory)])\n",
    "    print(f\"{prefix}{os.path.basename(directory)}: {num_files} files\")\n",
    "\n",
    "    for subdir in next(os.walk(directory))[1]:  # List subdirectories of the current directory\n",
    "        path = os.path.join(directory, subdir)  # Full path of the subdirectory\n",
    "        count_files_in_directory(path, prefix + \"  \")  # Recursively count in this subdirectory\n",
    "\n",
    "# Path to the dataset directory\n",
    "dataset_dir = './dataset'\n",
    "\n",
    "# Start the recursive count\n",
    "count_files_in_directory(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM_jg2OJZrrE"
   },
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "Now that we've downloaded the data we want, we do some basic preprocessing with functions from Torchvision.\n",
    "\n",
    "For the training data, we normalize and also use some data augmentation.\n",
    "\n",
    "For the validation set, we just normalize.\n",
    "\n",
    "# Problem 1 (Nothing to turn in)\n",
    "Read about this here: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A2YcP-DsrJa"
   },
   "source": [
    "# Make dataloaders out of our training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86War1vrEEt3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "\n",
    "# The directory that contains the data\n",
    "data_dir = 'dataset'\n",
    "\n",
    "# Now we apply the usual transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlzo1o99shqr"
   },
   "source": [
    "# Problem 2\n",
    "Write code that calls the dataloaders and displays some number of images, with their true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHrIuplTc2Ru"
   },
   "source": [
    "# Download a pre-trained model\n",
    "\n",
    "We will now download a pretrained model that has been trained on Imagenet. I recomend starting with Resnet18. See here for other larger or smaller pre-trained modfels https://pytorch.org/vision/stable/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3vyGOX3RYhs"
   },
   "outputs": [],
   "source": [
    "# Now we load a pre-trained model, and replace the last layer with a non-initialized linear layer.\n",
    "\n",
    "# This command loads a pre-trained model\n",
    "model_ft = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13GbkGRTtcaZ"
   },
   "source": [
    "# Problem 3\n",
    "\n",
    "Redefine the last layer of your neural network (called model_ft) to be a linear (fully connected layer) whose input size is whatever the input size is of the the current last layer, and whose output size is the number of labels your new data set has.\n",
    "\n",
    "You need to figure out how to do this. It's not too difficult. You need will use similar commands as you used in the last 2 homeworks in order to define a linear layer. The key will be to find out what the last layer is called, and also to find out what is its input size, so that you can properly define the size of the last fully connected (linear) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwucrYZybObc"
   },
   "source": [
    "# Training\n",
    "\n",
    "* We are going to fine-tune by training all the layers.\n",
    "\n",
    "* We can also freeze the old layers, and only update the last layers that we added. (This is not implemented below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-QsYuBCMAgN"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step() # updates the learning rate\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1I3mmjqdGoT"
   },
   "source": [
    "# Parameters of the optimization\n",
    "\n",
    "# Problem 4 (Optional)\n",
    "Explore choosing different learning rates or optimizers to see how things go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDSsV8q6RbNN"
   },
   "outputs": [],
   "source": [
    "# We need to set the loss function, the optimizer, and the learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# though we're fine tuning, we're updating all parameters\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# the scheduler decreases the learning rate by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM56-XrFdMy2"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxFpXJsTS4i_"
   },
   "outputs": [],
   "source": [
    "# Now we train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0nNjs-8ulBx"
   },
   "source": [
    "# Problem 5\n",
    "\n",
    "Report your accuracy on the testing set. You should compute this explicitly by running all your testing examples through the model and checking them against their true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmgRXICurg58"
   },
   "source": [
    "# Now let's visualize to see how well we did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB4a07eUuzze"
   },
   "source": [
    "# Problem 6\n",
    "\n",
    "Print out images from the test set, reporting the predicted labels and the true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ens6LEm3vCZ3"
   },
   "source": [
    "# Problem 7 (Optional)\n",
    "\n",
    "Experiment with some/all of the following:\n",
    "\n",
    "* Play with different pre-trained models\n",
    "* Experiment with different pre-processing of the data (e.g., turn data augmentation on or off).\n",
    "* Experiment with adding more/fewer layers, and/or layers of different size.\n",
    "* Fine tune by training everything or only the last (new) layer -- this requires figuring out how to only update some of the layers.\n",
    "* Try to reduce the number of images you use for training. How few can you use and still get good accuracy? Remember that you were all able to learn what a Goblin shark is with only one single example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrZ6E4T0sUxN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9nfyMqB5ze/fK9BqVUyXM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
